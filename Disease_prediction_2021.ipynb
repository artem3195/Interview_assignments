{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to predict new diseases for patients.\n",
    "\n",
    "Train data contains medical information for 2018-2019 period and labels with new diseases discovered in 2019.\n",
    "\n",
    "You are required to predict new diseases for 2020 using data for 2018-2019.\n",
    "\n",
    "Background\n",
    "Hierarchical condition category relies on ICD-10 coding to assign risk scores to patients. Each HCC is mapped to an ICD-10 code. Along with demographic factors (such as age and gender), insurance companies use HCC coding to assign patients a risk adjustment factor. It is very important to predict HCC coding to evaluate health risk of patients.\n",
    "\n",
    "Every HCC can be mapped to several ICDs but not every ICD has a corresponding HCC. It is a one to many connection for HCC to ICDs.\n",
    "\n",
    "We are providing ICD history of patients to predict their net new HCC coding for next year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T06:16:03.712597Z",
     "iopub.status.busy": "2021-10-18T06:16:03.712209Z",
     "iopub.status.idle": "2021-10-18T06:16:05.824087Z",
     "shell.execute_reply": "2021-10-18T06:16:05.823249Z",
     "shell.execute_reply.started": "2021-10-18T06:16:03.71249Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "from datetime import datetime\n",
    "\n",
    "import xgboost as xgb\n",
    "from joblib import dump, load\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, precision_score, recall_score\n",
    "\n",
    "data_path = '/kaggle/input/eastwood-and-cleef-ml-disease/drive-download-20210929T123943Z-001/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:06:31.687414Z",
     "iopub.status.busy": "2021-10-17T19:06:31.687129Z",
     "iopub.status.idle": "2021-10-17T19:06:31.717735Z",
     "shell.execute_reply": "2021-10-17T19:06:31.716346Z",
     "shell.execute_reply.started": "2021-10-17T19:06:31.68738Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"/kaggle/input/icd-decode-dict/icd_decode_di.pickle\", \"rb\")\n",
    "icd_decode_di = pickle.load(f)\n",
    "print(len(icd_decode_di))\n",
    "print(f\"Get sample value: {icd_decode_di['K8020']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan: \n",
    "\n",
    "1. Create statistical features using numerical data. \n",
    "2. Create embedding features using text data. \n",
    "3. Generate features for train (2018 year) and for test (2019 year).  \n",
    "4. Split data on train and validation datasets.  \n",
    "5. Train 30 xgboost models using training data for 2018 and labels for 2019.  \n",
    "6. Choose threshold on validation dataset.  \n",
    "7. Calculate AUC (mean) on validation dataset (65%).  \n",
    "8. Train on full dataset using data for 2018 and labels for 2019.  \n",
    "9. Make predictions for 2020 using selected thresholds and features generated for 2019.  \n",
    "\n",
    "ToDo:\n",
    "1. Create dynamic features - collect information how features have changed over time (for example, compare the first and last quarter).   \n",
    "2. Mean targeting encoding: (1) - select the most common icd for each hcc and generate embeddings for these icds. (2) - Calculate distances between members' icd embeddings and (1).   \n",
    "3. Tune xgboost params (especially, for the largest hcc classes). 1st step (use small number of n_estimators): max_depth, subsample, regularization;  2nd step (set larger number of n_estimators): add early stop; tune learning rate.  \n",
    "4. Use the original xgboost instead of sklMultiOutputClassifierearn (the problem is that xgboost from sklearn cannot work with None values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T08:44:06.634947Z",
     "iopub.status.busy": "2021-10-15T08:44:06.634551Z",
     "iopub.status.idle": "2021-10-15T08:44:06.656331Z",
     "shell.execute_reply": "2021-10-15T08:44:06.65504Z",
     "shell.execute_reply.started": "2021-10-15T08:44:06.634839Z"
    }
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools which used many times in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To work with DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:26.34476Z",
     "iopub.status.busy": "2021-10-16T15:56:26.344452Z",
     "iopub.status.idle": "2021-10-16T15:56:26.360143Z",
     "shell.execute_reply": "2021-10-16T15:56:26.359219Z",
     "shell.execute_reply.started": "2021-10-16T15:56:26.344732Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_date_diff(date_li):\n",
    "    '''calculate difference between two string dates, return days'''\n",
    "    \n",
    "    regexp = '\\d{4,4}\\-\\d{2,2}\\-\\d{2,2}'\n",
    "    date_flag = all(\n",
    "        [isinstance(c, str) and re.match(regexp,c) for c in date_li])\n",
    "    if date_flag: \n",
    "        date_li = [datetime.strptime(c,'%Y-%m-%d') for c in date_li]\n",
    "        date_diff = (date_li[1] - date_li[0]).days\n",
    "        return date_diff if date_diff >= 0 else None\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "def test_calc_date_diff(): \n",
    "    dates = ('2018-03-03', '2018-04-03')\n",
    "    date_diff = calc_date_diff(dates)\n",
    "    print(f'test_calc_date_diff:\\ndates:{dates}\\ndiff:{date_diff}')\n",
    "    return True\n",
    "\n",
    "print(test_calc_date_diff())\n",
    "\n",
    "def calc_ndays_in_hosptl(df, clmn1:str, clmn2:str, new_col:str):\n",
    "    '''calculate  difference between two string dates in df, \n",
    "    return df'''\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[new_col] = df[[clmn1, clmn2]].apply(\n",
    "        lambda x: calc_date_diff(x), axis= 1).values\n",
    "    return df\n",
    "\n",
    "def get_year_slice_df(\n",
    "    df,\n",
    "    date_start:str,\n",
    "    date_end:str,\n",
    "    year:str): \n",
    "    '''get df slice in a specific year'''\n",
    "    return df[df[[date_start, date_end]].apply(\n",
    "        lambda x: all(c.split('-')[0] == year for c in x), axis= 1)].reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To work with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:29.473394Z",
     "iopub.status.busy": "2021-10-16T15:56:29.473088Z",
     "iopub.status.idle": "2021-10-16T15:56:29.495493Z",
     "shell.execute_reply": "2021-10-16T15:56:29.494552Z",
     "shell.execute_reply.started": "2021-10-16T15:56:29.47336Z"
    }
   },
   "outputs": [],
   "source": [
    "pnct = string.punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_punctuation(word, punctuation= pnct):\n",
    "    return re.sub(f'[{punctuation}]','', word) if isinstance(word, str) else None\n",
    "\n",
    "def test_remove_punctuation(): \n",
    "    print('test remove punctuation')\n",
    "    t = '!anemia,'\n",
    "    print(t,'->', remove_punctuation(t))\n",
    "    #return True\n",
    "\n",
    "def prepare_text(text, stop_words= stop_words):\n",
    "    if isinstance(text, str):\n",
    "        # to lower register\n",
    "        text = text.lower()\n",
    "        # tokenize\n",
    "        text = word_tokenize(text)\n",
    "        # remove punctuation\n",
    "        text = [remove_punctuation(w) for w in text]\n",
    "        # filter out stop words\n",
    "        text = [w for w in text if not w in stop_words and w != '']\n",
    "        # stem (?) specific texts, can lose info..\n",
    "        \n",
    "        # Temp keep only words: \n",
    "        text = [w for w in text if w.isalpha()]\n",
    "        \n",
    "        return text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def test_prepare_text():\n",
    "    print('test prepare text:')\n",
    "    t = 'Displaced bicondylar fracture of left tibia, subsequent encounter for closed fracture with routine healing'\n",
    "    print(t, '->\\n', prepare_text(t))\n",
    "    return True\n",
    "\n",
    "print(test_prepare_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:33.211947Z",
     "iopub.status.busy": "2021-10-16T15:56:33.211583Z",
     "iopub.status.idle": "2021-10-16T15:56:33.221914Z",
     "shell.execute_reply": "2021-10-16T15:56:33.221018Z",
     "shell.execute_reply.started": "2021-10-16T15:56:33.211907Z"
    }
   },
   "outputs": [],
   "source": [
    "# can be one function \n",
    "def decode_and_collect_text_corpus(codes,\n",
    "                                   decodes_di): \n",
    "    '''get codes, decode them to text, then tokenize and clean text.\n",
    "       return list of lists\n",
    "    '''\n",
    "    num_missed = 0\n",
    "    corpus = []\n",
    "    for code in tqdm(codes): \n",
    "        decode = decodes_di.get(code)\n",
    "        if pd.isnull(decode): \n",
    "            num_missed+=1\n",
    "            continue\n",
    "        if isinstance(decode, str): \n",
    "            corpus.append(prepare_text(decode))\n",
    "    print(num_missed, len(corpus))\n",
    "    return corpus\n",
    "\n",
    "# not now:\n",
    "def dis_decode_and_collect_text_corpus(\n",
    "    code_df,\n",
    "    decodes_di): \n",
    "    '''get codes and chronic flag,\n",
    "       decode codes to text, then tokenize and clean text, add chronic flag.\n",
    "       return list of lists\n",
    "    '''\n",
    "    num_missed= 0\n",
    "    corpus = []\n",
    "    for code, chronic_flag in tqdm(code_df.values): \n",
    "        decode = decodes_di.get(code)\n",
    "        if pd.isnull(decode): \n",
    "            num_missed+=1\n",
    "            continue\n",
    "        if isinstance(decode, str): \n",
    "            decode = prepare_text(decode)\n",
    "            if isinstance(chronic_flag, str) and chronic_flag != 'Unknown': \n",
    "                # add chronic flag to prepared text of icd \n",
    "                decode = decode + [chronic_flag.lower()]\n",
    "            corpus.append(decode)\n",
    "    print(num_missed, len(corpus))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:35.4321Z",
     "iopub.status.busy": "2021-10-16T15:56:35.431772Z",
     "iopub.status.idle": "2021-10-16T15:56:35.439231Z",
     "shell.execute_reply": "2021-10-16T15:56:35.438241Z",
     "shell.execute_reply.started": "2021-10-16T15:56:35.432067Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adm_icd_embedding(icd_code,\n",
    "                          decodes_di,\n",
    "                          w2v_model,\n",
    "                          ): \n",
    "    '''get icd code and pre trained model.\n",
    "    return embedding'''\n",
    "    \n",
    "    decode = decodes_di.get(icd_code)\n",
    "    embngs_li = []\n",
    "    missed_words = 0\n",
    "    if isinstance(decode, str):\n",
    "        clnd_tokens_li = prepare_text(decode)\n",
    "        for w in clnd_tokens_li: \n",
    "            try: \n",
    "                embng = w2v_model.wv[w]\n",
    "                embngs_li.append(embng)\n",
    "            except Exception as e: \n",
    "                # print(e)\n",
    "                missed_words+=1\n",
    "        if len(embngs_li) > 0:\n",
    "            return sum(embngs_li)/len(embngs_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Icd_code to embeddings\n",
    "Get icd code from admissions and diseas data from 2018 to train word2vec model.  \n",
    "Better embeddings achived using only on admissions data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:43.038062Z",
     "iopub.status.busy": "2021-10-16T15:56:43.037772Z",
     "iopub.status.idle": "2021-10-16T15:56:43.109448Z",
     "shell.execute_reply": "2021-10-16T15:56:43.108838Z",
     "shell.execute_reply.started": "2021-10-16T15:56:43.038033Z"
    }
   },
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(\n",
    "    os.path.join(data_path, 'admissions_data.csv'))\n",
    "print(admissions_df.shape)\n",
    "admissions_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:45.963255Z",
     "iopub.status.busy": "2021-10-16T15:56:45.962948Z",
     "iopub.status.idle": "2021-10-16T15:56:46.306549Z",
     "shell.execute_reply": "2021-10-16T15:56:46.305937Z",
     "shell.execute_reply.started": "2021-10-16T15:56:45.963225Z"
    }
   },
   "outputs": [],
   "source": [
    "admissions_2018df = get_year_slice_df(\n",
    "    df= admissions_df, \n",
    "    date_start= 'admission_date',\n",
    "    date_end= 'discharge_date', \n",
    "    year= '2018'\n",
    "  )\n",
    "\n",
    "# save to encode feauters\n",
    "admission_types_set = set(\n",
    "    admissions_2018df.admission_type.unique()) \n",
    "print(f'Number admission types: {len(admission_types_set)}')\n",
    "\n",
    "print(admissions_2018df.shape,\n",
    "      admissions_2018df.member_id.nunique())\n",
    "admissions_2018df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adm_icd_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:49.410826Z",
     "iopub.status.busy": "2021-10-16T15:56:49.4102Z",
     "iopub.status.idle": "2021-10-16T15:56:49.42579Z",
     "shell.execute_reply": "2021-10-16T15:56:49.425006Z",
     "shell.execute_reply.started": "2021-10-16T15:56:49.410786Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect unique icd_codes\n",
    "adm_icd_code_2018 = admissions_2018df.icd_code.dropna().apply(\n",
    "    lambda x: x.split(';')).explode('icd_code').drop_duplicates()\n",
    "print(f'Unique icd_code in 2018: {len(adm_icd_code_2018)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:51.884297Z",
     "iopub.status.busy": "2021-10-16T15:56:51.883836Z",
     "iopub.status.idle": "2021-10-16T15:56:52.181315Z",
     "shell.execute_reply": "2021-10-16T15:56:52.180361Z",
     "shell.execute_reply.started": "2021-10-16T15:56:51.884265Z"
    }
   },
   "outputs": [],
   "source": [
    "# icd to tokens:\n",
    "adm_icd_corpus_2018 = decode_and_collect_text_corpus(\n",
    "    adm_icd_code_2018,\n",
    "    icd_decode_di\n",
    "    )\n",
    "print(adm_icd_corpus_2018[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:54.868735Z",
     "iopub.status.busy": "2021-10-16T15:56:54.868452Z",
     "iopub.status.idle": "2021-10-16T15:56:54.980526Z",
     "shell.execute_reply": "2021-10-16T15:56:54.979828Z",
     "shell.execute_reply.started": "2021-10-16T15:56:54.868699Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model only on adm_icd_corpus_2018\n",
    "adm_icd_wv_model = Word2Vec(\n",
    "    adm_icd_corpus_2018,\n",
    "    vector_size= 100,\n",
    "    min_count=1,\n",
    "    workers= 5,\n",
    "    window = 2,\n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:56:55.303007Z",
     "iopub.status.busy": "2021-10-16T15:56:55.301951Z",
     "iopub.status.idle": "2021-10-16T15:56:55.313166Z",
     "shell.execute_reply": "2021-10-16T15:56:55.312027Z",
     "shell.execute_reply.started": "2021-10-16T15:56:55.302964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fast check: distanse between v1 and v2 smaller then v1 and v3: \n",
    "v1 = get_adm_icd_embedding(\n",
    "    'A048',\n",
    "    icd_decode_di,\n",
    "    adm_icd_wv_model)\n",
    "\n",
    "v2 = get_adm_icd_embedding(\n",
    "    'A049',\n",
    "    icd_decode_di,\n",
    "    adm_icd_wv_model)\n",
    "\n",
    "v3 = get_adm_icd_embedding(\n",
    "    'Z9989',\n",
    "    icd_decode_di,\n",
    "    adm_icd_wv_model)\n",
    "\n",
    "print(\n",
    "prepare_text(icd_decode_di['A048']),'\\n',\n",
    "prepare_text(icd_decode_di['A049']),'\\n', \n",
    "prepare_text(icd_decode_di['Z9989'])\n",
    ")\n",
    "\n",
    "# unspecified - drop it\n",
    "print(cosine(v1,v2), cosine(v1, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from admissions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:59:53.205689Z",
     "iopub.status.busy": "2021-10-16T15:59:53.205012Z",
     "iopub.status.idle": "2021-10-16T15:59:53.219374Z",
     "shell.execute_reply": "2021-10-16T15:59:53.218525Z",
     "shell.execute_reply.started": "2021-10-16T15:59:53.205626Z"
    }
   },
   "outputs": [],
   "source": [
    "# funcs to get embdngs \n",
    "def combine_many_embdngs(\n",
    "    x,\n",
    "    decode_di:dict,\n",
    "    vw_model,\n",
    "    dim:int\n",
    "): \n",
    "    '''get average vector from icd_code embedings. \n",
    "    return averaged vector'''\n",
    "    \n",
    "    embdngs_li = []\n",
    "    for c in x: \n",
    "        if not pd.isnull(c):\n",
    "            embdng = get_adm_icd_embedding(\n",
    "                c,\n",
    "                decode_di, \n",
    "                vw_model) \n",
    "            if isinstance(embdng, np.ndarray): \n",
    "                embdngs_li.append(embdng)\n",
    "    l = len(embdngs_li)\n",
    "    if l > 0:\n",
    "        return sum(embdngs_li)/l\n",
    "    else: \n",
    "        return [None] * dim\n",
    "\n",
    "def generate_icd_embng_for_df(\n",
    "    df, \n",
    "    id_column:str,\n",
    "    emb_clmn:str,\n",
    "    decode_di:dict, \n",
    "    wv_model, # trained model to get embdngs\n",
    "    dim:int, # vector size\n",
    "    emb_feature_name:str):\n",
    "    '''group by id and generate avereged embedding. \n",
    "    return df with id and embeddings'''\n",
    "\n",
    "    df = df[[id_column, emb_clmn]].dropna().copy()\n",
    "\n",
    "    df[emb_clmn] = df[emb_clmn].str.split(';')\n",
    "    df = df.explode(emb_clmn)\n",
    "\n",
    "    df.drop_duplicates(\n",
    "        inplace= True)\n",
    "    df.reset_index(\n",
    "        drop= True,\n",
    "        inplace= True)\n",
    "    \n",
    "    # group by id\n",
    "    df = df.groupby(id_column)[emb_clmn].apply(\n",
    "        lambda x: combine_many_embdngs(\n",
    "            x,\n",
    "            decode_di,\n",
    "            wv_model,\n",
    "            dim\n",
    "        )\n",
    "    ).copy()\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    # adding embeddings columns\n",
    "    new_cols = [f'{emb_feature_name}_{i}' for i in range(1,dim + 1)]\n",
    "    df[new_cols] = pd.DataFrame(\n",
    "        df[emb_clmn].to_list(), \n",
    "        index = df.index).values\n",
    "    \n",
    "    # some codes have no embeddings\n",
    "    prev_num_rows = df.shape[0]\n",
    "    df.dropna(inplace= True)\n",
    "    print(f'Percent of Null embdngs: {(1 - prev_num_rows/df.shape[0]):.2f}')\n",
    "    \n",
    "    df.drop(emb_clmn, axis= 1, inplace= True)\n",
    "    df.reset_index(drop= True, inplace= True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:59:54.125274Z",
     "iopub.status.busy": "2021-10-16T15:59:54.124697Z",
     "iopub.status.idle": "2021-10-16T15:59:55.461228Z",
     "shell.execute_reply": "2021-10-16T15:59:55.460474Z",
     "shell.execute_reply.started": "2021-10-16T15:59:54.125224Z"
    }
   },
   "outputs": [],
   "source": [
    "adm_icd_embngs_2018df = generate_icd_embng_for_df(\n",
    "    admissions_2018df,\n",
    "    id_column = 'member_id',\n",
    "    emb_clmn = 'icd_code', \n",
    "    decode_di = icd_decode_di, \n",
    "    wv_model = adm_icd_wv_model,\n",
    "    dim = 100, \n",
    "    emb_feature_name = 'icd_embdng'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_Adm_Features: \n",
    "    '''Generate feares froom admissons data. return df'''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 date_strat:str,\n",
    "                 date_end:str,\n",
    "                 year:str, \n",
    "                 adm_types_set:set, \n",
    "                 id_column: str, \n",
    "                 emb_clmn: str, \n",
    "                 decode_di: dict, \n",
    "                 wv_model, \n",
    "                 dim,\n",
    "                 emb_feature_name\n",
    "                ): \n",
    "\n",
    "        self.df = df\n",
    "        self.date_strat = date_strat\n",
    "        self.date_end = date_end\n",
    "        self.year = year\n",
    "        self.adm_types_set = adm_types_set \n",
    "        self.id_column = id_column\n",
    "        self.emb_clmn = emb_clmn\n",
    "        self.decode_di = decode_di\n",
    "        self.wv_model = wv_model\n",
    "        self.dim = dim\n",
    "        self.emb_feature_name = emb_feature_name\n",
    "        \n",
    "    def adm_hosptl_day_agg_rules(self, x): \n",
    "        '''rules to aggregate days in hospital'''       \n",
    "\n",
    "        d = {\n",
    "            'num_apprnc_in_hosptl'   : x['admission_date'].count(),\n",
    "            'sum_readmissions'       : x['enc_is_readmission'].sum(), \n",
    "            'sum_admission_transfer' : x['enc_admission_transfer'].sum(),\n",
    "            \n",
    "            'max_day_in_hosptl'    : x['day_in_hosptl'].max(),\n",
    "            'mean_day_in_hosptl'   : x['day_in_hosptl'].mean(),\n",
    "        }\n",
    "        return pd.Series(d, index= d.keys())\n",
    "\n",
    "    def adm_agg_hosptl_day_df(self, df):\n",
    "        '''aggregate days in hospital'''\n",
    "        \n",
    "        return df.groupby('member_id').apply(\n",
    "            self.adm_hosptl_day_agg_rules).reset_index()\n",
    "    \n",
    "    def generate_features(self): \n",
    "        \n",
    "        # get data from specific date\n",
    "        self.df = get_year_slice_df(\n",
    "            self.df,\n",
    "            self.date_strat,\n",
    "            self.date_end, \n",
    "            self.year\n",
    "          )\n",
    "        \n",
    "        if self.df.shape[0] == 0: \n",
    "            print(f'df shape equals 0')\n",
    "            return self.df\n",
    "\n",
    "        # calculate new feature - day in hospital\n",
    "        self.df = calc_ndays_in_hosptl(\n",
    "            df = self.df,\n",
    "            clmn1 = self.date_strat,\n",
    "            clmn2 = self.date_end,\n",
    "            new_col = 'day_in_hosptl'\n",
    "            )\n",
    "        \n",
    "        # encode words\n",
    "        self.df['enc_is_readmission'] = self.df.is_readmission.replace(\n",
    "            {'No':0, 'Yes':1})\n",
    "        self.df['enc_admission_transfer'] = self.df.er_to_inp_admission_transfer.replace(\n",
    "            {'N':0,'Y':1})\n",
    "        \n",
    "        # exclude unknown admission_type \n",
    "        self.df.admission_type = self.df.admission_type.apply(\n",
    "            lambda x: x if x in self.adm_types_set else None)\n",
    "        \n",
    "        # get dummies from admission_type\n",
    "        dummy_df = pd.get_dummies(\n",
    "            self.df.set_index('member_id').admission_type, \n",
    "            prefix= 'adm_type').reset_index()\n",
    "        \n",
    "        # aggregate dummies\n",
    "        dummy_df = dummy_df.groupby('member_id').sum()\n",
    "    \n",
    "        # generate and agg embeddings: \n",
    "        icd_embngs_df = generate_icd_embng_for_df(\n",
    "            self.df,\n",
    "            self.id_column,\n",
    "            self.emb_clmn, \n",
    "            self.decode_di, \n",
    "            self.wv_model,\n",
    "            self.dim, \n",
    "            self.emb_feature_name\n",
    "        )\n",
    "    \n",
    "        # aggregate features \n",
    "        self.df = self.adm_agg_hosptl_day_df(self.df)\n",
    "    \n",
    "        # combine features \n",
    "        print(f'Dummies shape matched: {dummy_df.shape[0] == self.df.shape[0]}')\n",
    "        \n",
    "        self.df = self.df.merge(\n",
    "            dummy_df,\n",
    "            on = 'member_id', \n",
    "            how = 'inner'\n",
    "        )\n",
    "        \n",
    "        self.df = self.df.merge(\n",
    "            icd_embngs_df, \n",
    "            on = 'member_id', \n",
    "            how= 'left'\n",
    "        )\n",
    "        print(f'Unique id: {self.df.member_id.nunique()}, shape: {self.df.shape}')\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_features_2018df = Generate_Adm_Features(\n",
    "    df = admissions_df, \n",
    "    date_strat = 'admission_date', \n",
    "    date_end='discharge_date',\n",
    "    year = '2018',\n",
    "    adm_types_set = admission_types_set,\n",
    "    id_column = 'member_id',\n",
    "    emb_clmn = 'icd_code', \n",
    "    decode_di = icd_decode_di, \n",
    "    wv_model = adm_icd_wv_model,\n",
    "    dim = 100, \n",
    "    emb_feature_name = 'icd_embdng').generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_features_2019df = Generate_Adm_Features(\n",
    "    df = admissions_df, \n",
    "    date_strat = 'admission_date', \n",
    "    date_end='discharge_date',\n",
    "    year = '2019',\n",
    "    adm_types_set = admission_types_set,\n",
    "    id_column = 'member_id',\n",
    "    emb_clmn = 'icd_code', \n",
    "    decode_di = icd_decode_di, \n",
    "    wv_model = adm_icd_wv_model,\n",
    "    dim = 100, \n",
    "    emb_feature_name = 'icd_embdng').generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(adm_features_2018df.columns) - \n",
    "      set(adm_features_2019df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_features_2018df.to_pickle(\n",
    "    '/kaggle/working/adm_features_2018df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_features_2019df.to_pickle(\n",
    "    '/kaggle/working/adm_features_2019df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:57:29.460691Z",
     "iopub.status.busy": "2021-10-10T08:57:29.459939Z",
     "iopub.status.idle": "2021-10-10T08:57:29.46475Z",
     "shell.execute_reply": "2021-10-10T08:57:29.463954Z",
     "shell.execute_reply.started": "2021-10-10T08:57:29.460644Z"
    }
   },
   "source": [
    "# diseas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. icd_chronic_or_acute != hcc_chronic_or_acute 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:57:20.985599Z",
     "iopub.status.busy": "2021-10-16T15:57:20.984845Z",
     "iopub.status.idle": "2021-10-16T15:57:21.96908Z",
     "shell.execute_reply": "2021-10-16T15:57:21.968046Z",
     "shell.execute_reply.started": "2021-10-16T15:57:20.985554Z"
    }
   },
   "outputs": [],
   "source": [
    "diseas_df = pd.read_csv(\n",
    "    os.path.join(data_path, 'disease_data.csv'))\n",
    "print(diseas_df.shape, diseas_df.member_id.nunique())\n",
    "diseas_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:57:24.425323Z",
     "iopub.status.busy": "2021-10-16T15:57:24.424532Z",
     "iopub.status.idle": "2021-10-16T15:57:24.505281Z",
     "shell.execute_reply": "2021-10-16T15:57:24.504644Z",
     "shell.execute_reply.started": "2021-10-16T15:57:24.425266Z"
    }
   },
   "outputs": [],
   "source": [
    "diseas_df.hcc_chronic_or_acute.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:57:25.48613Z",
     "iopub.status.busy": "2021-10-16T15:57:25.485362Z",
     "iopub.status.idle": "2021-10-16T15:57:25.537847Z",
     "shell.execute_reply": "2021-10-16T15:57:25.536931Z",
     "shell.execute_reply.started": "2021-10-16T15:57:25.486067Z"
    }
   },
   "outputs": [],
   "source": [
    "hcc_cat_unique = list(diseas_df[\n",
    "    diseas_df.year_of_service == 2018].hcc_code.dropna().unique())\n",
    "print(len(hcc_cat_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T15:57:27.526101Z",
     "iopub.status.busy": "2021-10-16T15:57:27.525603Z",
     "iopub.status.idle": "2021-10-16T15:57:27.550392Z",
     "shell.execute_reply": "2021-10-16T15:57:27.549752Z",
     "shell.execute_reply.started": "2021-10-16T15:57:27.526057Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generate_Hcc_Features():\n",
    "    '''Generate hcc features for specific date.\n",
    "    return df''' \n",
    "        \n",
    "    def __init__(\n",
    "        self, \n",
    "        df, \n",
    "        year:int, \n",
    "        clmn_id:str,\n",
    "        hcc_catgs:str,\n",
    "        embdng_clmn:str, \n",
    "        decode_di:dict,\n",
    "        wv_model, \n",
    "        dim:int,\n",
    "    ):\n",
    "        \n",
    "        self.df = df\n",
    "        self.year = year\n",
    "        self.clmn_id = clmn_id\n",
    "        self.hcc_catgs = hcc_catgs\n",
    "        self.embdng_clmn = embdng_clmn\n",
    "        self.decode_di = decode_di\n",
    "        self.wv_model = wv_model\n",
    "        self.dim = dim        \n",
    "        \n",
    "    def left_merg(self, df1, df2):\n",
    "        return df1.merge(df2, on = self.clmn_id, how= 'left')    \n",
    "    \n",
    "    def stats_icc_hcc(self, df): \n",
    "        d = {\n",
    "            'dis_num_icd': df['icd_code'].dropna().count(),\n",
    "            'dis_num_unique_icd' : df['icd_code'].nunique(),\n",
    "\n",
    "            'dis_num_hcc': df['hcc_code'].dropna().count(),\n",
    "            'dis_num_unique_hcc' : df['hcc_code'].nunique()\n",
    "        }\n",
    "        return pd.Series(d, index= d.keys())\n",
    "\n",
    "    def agg_stats_icc_hcc(self, df):\n",
    "            '''aggregate icc hcc info'''\n",
    "\n",
    "            return df.groupby(self.clmn_id).apply(\n",
    "                self.stats_icc_hcc).reset_index()\n",
    "            \n",
    "    def count_nflag(\n",
    "        self, \n",
    "        df, \n",
    "        clmn_id:str,\n",
    "        clmn_flag:str, \n",
    "        flag:str, \n",
    "        new_clmn_name:str):\n",
    "        '''Count n flag for id. return df'''\n",
    "        \n",
    "        df = df[[clmn_id, clmn_flag]].copy()\n",
    "        \n",
    "        df = df.groupby(clmn_id)[clmn_flag].apply(\n",
    "            lambda x: sum([True if isinstance(c,str) \n",
    "                                and (c == flag) else False for c in x]))\n",
    "        df = df.reset_index()\n",
    "        df.columns = [clmn_id, new_clmn_name]\n",
    "        return df\n",
    "    \n",
    "    def generate_hcc_dummies(\n",
    "        self,\n",
    "        df):\n",
    "        '''generate dummies variables'''\n",
    "        \n",
    "        df = df.copy()\n",
    "        # get catgs only from train\n",
    "        df['hcc_code'] = df['hcc_code'].apply(\n",
    "            lambda x: x if x in self.hcc_catgs else None)\n",
    "\n",
    "        df['hcc_code'] = df['hcc_code'].apply(\n",
    "            lambda x: str(int(x)) if not pd.isnull(x) else x)\n",
    "\n",
    "        hcc_dumm_df = pd.get_dummies(\n",
    "                    df.set_index(self.clmn_id).hcc_code, \n",
    "                    prefix= 'dis_hcc_code').reset_index()\n",
    "        \n",
    "        hcc_dumm_df = hcc_dumm_df.groupby(\n",
    "            self.clmn_id).sum().reset_index()\n",
    "        \n",
    "        return hcc_dumm_df\n",
    "    \n",
    "    def generate_features(self): \n",
    "        \n",
    "        # get df on a specific date\n",
    "        self.df = self.df[\n",
    "            self.df.year_of_service == self.year].copy()\n",
    "        \n",
    "        self.df.reset_index(drop= True, inplace= True)\n",
    "        \n",
    "        # count statistics on icd, hcc codes\n",
    "        stats_code_df = self.agg_stats_icc_hcc(self.df)\n",
    "            \n",
    "        # count flag\n",
    "        n_hcc_chronic_df = self.count_nflag(\n",
    "            df = self.df, \n",
    "            clmn_id = self.clmn_id,\n",
    "            clmn_flag = 'hcc_chronic_or_acute',\n",
    "            flag = 'Chronic',\n",
    "            new_clmn_name = 'dis_hcc_nchronic'\n",
    "        )     \n",
    "        \n",
    "        n_hcc_acute_df = self.count_nflag(\n",
    "            df = self.df, \n",
    "            clmn_id = self.clmn_id,\n",
    "            clmn_flag = 'hcc_chronic_or_acute',\n",
    "            flag = 'Acute',\n",
    "            new_clmn_name = 'dis_hcc_acute'\n",
    "        )\n",
    "        \n",
    "        # hcc dummies\n",
    "        hcc_dumm_df = self.generate_hcc_dummies(self.df)\n",
    "        \n",
    "        # icd embngs\n",
    "        dis_icd_embngs_df = generate_icd_embng_for_df(\n",
    "            df = self.df,\n",
    "            id_column = self.clmn_id,\n",
    "            emb_clmn = self.embdng_clmn, \n",
    "            decode_di = self.decode_di, \n",
    "            wv_model =  self.wv_model,\n",
    "            dim = self.dim, \n",
    "            emb_feature_name = 'dis_icd_embdng'\n",
    "        )             \n",
    "        \n",
    "        features_df = self.df[[self.clmn_id]].copy()\n",
    "        features_df.drop_duplicates(inplace= True)\n",
    "        features_df.reset_index(inplace= True, drop= True)\n",
    "        \n",
    "        # merge features\n",
    "        features_df = self.left_merg(\n",
    "            features_df,\n",
    "            stats_code_df)\n",
    "        \n",
    "        features_df = self.left_merg(\n",
    "            features_df,\n",
    "            n_hcc_chronic_df)\n",
    "        \n",
    "        features_df = self.left_merg(\n",
    "            features_df,\n",
    "            n_hcc_acute_df)\n",
    "        \n",
    "        features_df = self.left_merg(\n",
    "            features_df, \n",
    "            hcc_dumm_df)\n",
    "        \n",
    "        features_df = self.left_merg(\n",
    "            features_df, \n",
    "            dis_icd_embngs_df)\n",
    "        \n",
    "        return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:00:04.177938Z",
     "iopub.status.busy": "2021-10-16T16:00:04.177647Z",
     "iopub.status.idle": "2021-10-16T16:02:01.846001Z",
     "shell.execute_reply": "2021-10-16T16:02:01.84507Z",
     "shell.execute_reply.started": "2021-10-16T16:00:04.17791Z"
    }
   },
   "outputs": [],
   "source": [
    "dis_features_2018df = Generate_Hcc_Features(\n",
    "    df = diseas_df, \n",
    "    year = 2018, \n",
    "    clmn_id = 'member_id', \n",
    "    hcc_catgs = hcc_cat_unique,\n",
    "    embdng_clmn = 'icd_code',\n",
    "    decode_di = icd_decode_di, \n",
    "    wv_model = adm_icd_wv_model, \n",
    "    dim = 100).generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:02:01.847927Z",
     "iopub.status.busy": "2021-10-16T16:02:01.847651Z",
     "iopub.status.idle": "2021-10-16T16:02:01.869836Z",
     "shell.execute_reply": "2021-10-16T16:02:01.869277Z",
     "shell.execute_reply.started": "2021-10-16T16:02:01.847885Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dis_features_2018df.shape)\n",
    "dis_features_2018df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:02:01.871402Z",
     "iopub.status.busy": "2021-10-16T16:02:01.870727Z",
     "iopub.status.idle": "2021-10-16T16:04:44.140837Z",
     "shell.execute_reply": "2021-10-16T16:04:44.140079Z",
     "shell.execute_reply.started": "2021-10-16T16:02:01.871371Z"
    }
   },
   "outputs": [],
   "source": [
    "dis_features_2019df = Generate_Hcc_Features(\n",
    "    df = diseas_df, \n",
    "    year = 2019, \n",
    "    clmn_id = 'member_id', \n",
    "    hcc_catgs = hcc_cat_unique,\n",
    "    embdng_clmn = 'icd_code',\n",
    "    decode_di = icd_decode_di, \n",
    "    wv_model = adm_icd_wv_model, \n",
    "    dim = 100).generate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.143671Z",
     "iopub.status.busy": "2021-10-16T16:04:44.142847Z",
     "iopub.status.idle": "2021-10-16T16:04:44.167395Z",
     "shell.execute_reply": "2021-10-16T16:04:44.166507Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.143621Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dis_features_2019df.shape)\n",
    "dis_features_2019df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.16908Z",
     "iopub.status.busy": "2021-10-16T16:04:44.16875Z",
     "iopub.status.idle": "2021-10-16T16:04:44.175838Z",
     "shell.execute_reply": "2021-10-16T16:04:44.174688Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.169039Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    set(dis_features_2018df.columns) - set(dis_features_2019df.columns))\n",
    "print(\n",
    "      set(dis_features_2019df.columns) - set(dis_features_2018df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.177634Z",
     "iopub.status.busy": "2021-10-16T16:04:44.177317Z",
     "iopub.status.idle": "2021-10-16T16:04:44.212321Z",
     "shell.execute_reply": "2021-10-16T16:04:44.211569Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.177595Z"
    }
   },
   "outputs": [],
   "source": [
    "dis_features_2019df['dis_hcc_code_160'] = 0\n",
    "dis_features_2019df = dis_features_2019df[\n",
    "    dis_features_2018df.columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.213567Z",
     "iopub.status.busy": "2021-10-16T16:04:44.213353Z",
     "iopub.status.idle": "2021-10-16T16:04:44.220193Z",
     "shell.execute_reply": "2021-10-16T16:04:44.219218Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.213542Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    set(dis_features_2018df.columns) - set(dis_features_2019df.columns))\n",
    "print(\n",
    "      set(dis_features_2019df.columns) - set(dis_features_2018df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.221632Z",
     "iopub.status.busy": "2021-10-16T16:04:44.22138Z",
     "iopub.status.idle": "2021-10-16T16:04:44.263186Z",
     "shell.execute_reply": "2021-10-16T16:04:44.262399Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.221608Z"
    }
   },
   "outputs": [],
   "source": [
    "dis_features_2018df.to_pickle(\n",
    "    '/kaggle/working/dis_features_2018df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:04:44.264658Z",
     "iopub.status.busy": "2021-10-16T16:04:44.264449Z",
     "iopub.status.idle": "2021-10-16T16:04:44.322655Z",
     "shell.execute_reply": "2021-10-16T16:04:44.321908Z",
     "shell.execute_reply.started": "2021-10-16T16:04:44.264633Z"
    }
   },
   "outputs": [],
   "source": [
    "dis_features_2019df.to_pickle(\n",
    "    '/kaggle/working/dis_features_2019df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_df = pd.read_csv(os.path.join(data_path, 'labs_data.csv'))\n",
    "print(labs_df.shape)\n",
    "labs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_Labs_Features():\n",
    "    '''Generate labs features.return df'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df, \n",
    "        year: int\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.year = year\n",
    "    \n",
    "    def correct_test_value(self, df):\n",
    "        '''Initial value seems to be from other scale. return df.'''\n",
    "        df = df.copy()\n",
    "        df['correct_res_val'] = df.result_value.apply(\n",
    "            lambda x: x/1000 if not pd.isnull(x) else x).values\n",
    "        return df\n",
    "\n",
    "    def flag_res_val(self, x):\n",
    "        '''Convert res test val to category'''\n",
    "        \n",
    "        res_val, lower_bound, upper_bound = x\n",
    "        if res_val <= lower_bound:\n",
    "            return 'lower'\n",
    "        elif res_val >= upper_bound: \n",
    "            return 'higher'\n",
    "        elif lower_bound < res_val < upper_bound:\n",
    "            return 'normal'\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def add_test_result_clmn(self, df):\n",
    "        '''Add new column with category for test value'''\n",
    "\n",
    "        df = df.copy()\n",
    "        df['test_result'] = df[[\n",
    "            'correct_res_val', \n",
    "            'normal_low_value_numeric',\n",
    "            'normal_high_value_numeric']].apply(\n",
    "            lambda x: self.flag_res_val(x), axis= 1)\n",
    "        return df\n",
    "\n",
    "    def test_agg_rules(self, df): \n",
    "        d = {\n",
    "            'n_test' : df['test_result'].count(),\n",
    "            'n_normal_test': sum(df['test_result'] == 'normal'),\n",
    "            'n_higher_test': sum(df['test_result'] == 'higher'),\n",
    "            'n_lower_test': sum(df['test_result'] == 'lower'),\n",
    "        }\n",
    "        return pd.Series(d, index= d.keys())\n",
    "\n",
    "    def agg_test_results(self, df):\n",
    "            '''Aggregate test results. return df'''\n",
    "            \n",
    "            return df.groupby('member_id').apply(\n",
    "                self.test_agg_rules).reset_index()    \n",
    "        \n",
    "    def generate_features(self): \n",
    "        \n",
    "        # get specific date:\n",
    "        self.df = self.df[self.df.date_of_service.apply(\n",
    "            lambda x: True if isinstance(x,str) and \n",
    "                      x.split('-')[0] == str(self.year) else False)].copy()\n",
    "        \n",
    "        self.df.reset_index(\n",
    "            drop= True,\n",
    "            inplace= True\n",
    "        )\n",
    "        \n",
    "        # add corrected test val\n",
    "        self.df = self.correct_test_value(self.df)\n",
    "        \n",
    "        # add test result categories clmn:\n",
    "        self.df = self.add_test_result_clmn(self.df)\n",
    "        \n",
    "        # aggregate \n",
    "        self.df = self.agg_test_results(self.df)\n",
    "        print(f'Unique member_id: {self.df.member_id.nunique()}')\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_feature_2018_df = Generate_/kaggle/Features(\n",
    "    labs_df, \n",
    "    2018).generate_features()\n",
    "print(labs_feature_2018_df.shape)\n",
    "labs_feature_2018_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_feature_2019_df = Generate_Labs_Features(\n",
    "    labs_df, \n",
    "    2019).generate_features()\n",
    "print(labs_feature_2019_df.shape)\n",
    "labs_feature_2019_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_feature_2018_df.to_pickle(\n",
    "    '/kaggle/working/labs_feature_2018_df.pickle')\n",
    "labs_feature_2019_df.to_pickle(\n",
    "    '/kaggle/working/labs_feature_2019_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:11.659034Z",
     "iopub.status.busy": "2021-10-16T16:06:11.658654Z",
     "iopub.status.idle": "2021-10-16T16:06:11.760945Z",
     "shell.execute_reply": "2021-10-16T16:06:11.760153Z",
     "shell.execute_reply.started": "2021-10-16T16:06:11.658996Z"
    }
   },
   "outputs": [],
   "source": [
    "patients_df =  pd.read_csv(os.path.join(data_path, 'patients_data.csv'))\n",
    "print(patients_df.shape)\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:12.87959Z",
     "iopub.status.busy": "2021-10-16T16:06:12.879314Z",
     "iopub.status.idle": "2021-10-16T16:06:12.890412Z",
     "shell.execute_reply": "2021-10-16T16:06:12.88977Z",
     "shell.execute_reply.started": "2021-10-16T16:06:12.879561Z"
    }
   },
   "outputs": [],
   "source": [
    "patients_df.insurance_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:15.09266Z",
     "iopub.status.busy": "2021-10-16T16:06:15.091771Z",
     "iopub.status.idle": "2021-10-16T16:06:15.117827Z",
     "shell.execute_reply": "2021-10-16T16:06:15.116842Z",
     "shell.execute_reply.started": "2021-10-16T16:06:15.092621Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictionaries to decode:\n",
    "unique_ins_comp = patients_df.insurance_company.unique()\n",
    "l = len(unique_ins_comp)\n",
    "ins_di = {key:val for key, val in zip(\n",
    "    unique_ins_comp, [f'ins_cmp_{i}' for i in range(l)])}\n",
    "print(ins_di,'\\n')\n",
    "\n",
    "unique_ins_type = patients_df.insurance_type.unique()\n",
    "l_type = len(unique_ins_type)\n",
    "ins_type_di = {key:val for key, val in zip(\n",
    "    unique_ins_type, [i for i in range(l_type)])}\n",
    "print(ins_type_di,'\\n')\n",
    "\n",
    "unique_ins_pbp_type = patients_df.pbp_type.dropna().unique()\n",
    "l_pbp = len(unique_ins_pbp_type)\n",
    "print(l_pbp)\n",
    "pbp_type_di = {key:val for key, val in zip(\n",
    "    unique_ins_pbp_type, [f'pbp_type_{i}' for i in range(l_pbp)])}\n",
    "print(pbp_type_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:18.911924Z",
     "iopub.status.busy": "2021-10-16T16:06:18.91094Z",
     "iopub.status.idle": "2021-10-16T16:06:18.936951Z",
     "shell.execute_reply": "2021-10-16T16:06:18.936277Z",
     "shell.execute_reply.started": "2021-10-16T16:06:18.911865Z"
    }
   },
   "outputs": [],
   "source": [
    "for clmn in patients_df.columns[1:]:\n",
    "    print(f'{clmn} nunique vals: {patients_df[clmn].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:24.204563Z",
     "iopub.status.busy": "2021-10-16T16:06:24.203772Z",
     "iopub.status.idle": "2021-10-16T16:06:24.214284Z",
     "shell.execute_reply": "2021-10-16T16:06:24.213321Z",
     "shell.execute_reply.started": "2021-10-16T16:06:24.204529Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generate_Patients_features():\n",
    "    '''Generate patients features. return df'''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df,):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate(self):\n",
    "        \n",
    "        self.df['encode_patient_gender'] = self.df.patient_gender.apply(\n",
    "            lambda x: 1 if x == 'M' else 0)\n",
    "        \n",
    "        self.df['enc_ins_comp'] = self.df.insurance_company.apply(\n",
    "            lambda x: ins_di.get(x))\n",
    "        \n",
    "        self.df['enc_ins_type'] = self.df.insurance_type.apply(\n",
    "            lambda x: ins_type_di.get(x))\n",
    "        \n",
    "        self.df['enc_ins_pbp'] = self.df.pbp_type.apply(\n",
    "            lambda x: pbp_type_di.get(x))\n",
    "        \n",
    "        ins_comp_dummy = pd.get_dummies(\n",
    "            self.df.set_index('member_id').enc_ins_comp).reset_index()\n",
    "        \n",
    "        pbp_dummy = pd.get_dummies(\n",
    "            self.df.set_index('member_id').enc_ins_pbp).reset_index()        \n",
    "                \n",
    "        feature_clmns = ['member_id',\n",
    "                         'encode_patient_gender',\n",
    "                         'enc_ins_type'\n",
    "                        ]\n",
    "        # merge dummies\n",
    "        feature_df = self.df[feature_clmns].merge(\n",
    "            ins_comp_dummy, \n",
    "            on = 'member_id'\n",
    "        )\n",
    "        \n",
    "        feature_df = feature_df.merge(\n",
    "            pbp_dummy, \n",
    "            on = 'member_id'\n",
    "        )\n",
    "            \n",
    "        return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:06:27.067226Z",
     "iopub.status.busy": "2021-10-16T16:06:27.06629Z",
     "iopub.status.idle": "2021-10-16T16:06:27.186645Z",
     "shell.execute_reply": "2021-10-16T16:06:27.185618Z",
     "shell.execute_reply.started": "2021-10-16T16:06:27.067178Z"
    }
   },
   "outputs": [],
   "source": [
    "patients_feature_df = Generate_Patients_features(\n",
    "    patients_df).generate()\n",
    "print(patients_feature_df.shape)\n",
    "patients_feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:07:22.809987Z",
     "iopub.status.busy": "2021-10-16T16:07:22.809684Z",
     "iopub.status.idle": "2021-10-16T16:07:22.826634Z",
     "shell.execute_reply": "2021-10-16T16:07:22.825639Z",
     "shell.execute_reply.started": "2021-10-16T16:07:22.809955Z"
    }
   },
   "outputs": [],
   "source": [
    "patients_feature_df.to_pickle(\n",
    "    '/kaggle/working/patients_feature_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prescription_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_df = pd.read_csv(os.path.join(\n",
    "    data_path, 'prescriptions_data.csv'))\n",
    "print(prescriptions_df.shape)\n",
    "\n",
    "prescriptions_df.days_supply= prescriptions_df.days_supply.apply(\n",
    "    lambda x: int(x) if not pd.isnull(x) else x)\n",
    "\n",
    "# execute drug name\n",
    "prescriptions_df['short_drug_name'] = prescriptions_2018df.drug_name.apply(\n",
    "    lambda x: x.split()[0] if isinstance(x,str) else x)\n",
    "\n",
    "# clean days_supply; metric_quantity\n",
    "prescriptions_df['clnd_days_supply'] = prescriptions_df.days_supply.apply(\n",
    "    lambda x: None if pd.isnull(x) or (x < 0) or (x > 364) else x)\n",
    "prescriptions_df['clnd_metric_quantity'] = prescriptions_df.metric_quantity.apply(\n",
    "    lambda x: None if pd.isnull(x) or (x < 0) or (x > 364) else x)\n",
    "\n",
    "# check percent of Null\n",
    "ds_null1 = prescriptions_df.days_supply.isnull().mean()\n",
    "ds_null2 = prescriptions_df.clnd_days_supply.isnull().mean()\n",
    "\n",
    "mq_null1 = prescriptions_df.metric_quantity.isnull().mean()\n",
    "mq_null2 = prescriptions_df.clnd_metric_quantity.isnull().mean()\n",
    "\n",
    "print('Columns changes after cleaning:')\n",
    "print(f'days_supply percent of null:{ds_null1:.2} -> {ds_null2:.2}')\n",
    "print(f'days_metric_quantity of null:{mq_null1:.2} -> {mq_null2:.2}')\n",
    "\n",
    "prescriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug names embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from 2018 \n",
    "prescriptions_2018df = prescriptions_df[prescriptions_df.date_filled.apply(\n",
    "    lambda x: x.split('-')[0] == '2018')].reset_index(drop= True).copy()\n",
    "\n",
    "# train model on 2018 drugs name corpus\n",
    "short_drug_names = prescriptions_2018df.short_drug_name.drop_duplicates().dropna()\n",
    "short_drug_names = short_drug_names.values\n",
    "drug_corpus = [row.split(',') for row in short_drug_names]\n",
    "\n",
    "# drugs name to vectors: \n",
    "drugs_model = Word2Vec(\n",
    "    drug_corpus,vector_size= 50,\n",
    "    min_count=1,\n",
    "    workers=3,\n",
    "    window = 1)\n",
    "\n",
    "# embeddings dict\n",
    "drg_emdngs = {}\n",
    "missed_drugs= []\n",
    "for short_name in short_drug_names:\n",
    "    try:\n",
    "        drg_emdngs[short_name] = drugs_model.wv[short_name]\n",
    "    except: \n",
    "        missed_drugs.append(short_name)\n",
    "        continue\n",
    "print(f'Missed drugs names {len(missed_drugs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "v1 = drugs_model.wv['CYCLOSPORINE']\n",
    "v2 = drugs_model.wv['OMEPRAZOLE']\n",
    "v3 = drugs_model.wv['METOPROLOL']\n",
    "\n",
    "w1 = drugs_model.wv['OMEPRAZOLE']\n",
    "w2 = drugs_model.wv['ALLOPURINOL']\n",
    "w3 = drugs_model.wv['METOPROLOL']\n",
    "\n",
    "k1 = drugs_model.wv['ATORVASTATIN']\n",
    "k2 = drugs_model.wv['CYCLOBENZAPRINE']\n",
    "\n",
    "v = (v1+v2+v3)/3\n",
    "w = (w1+w2+w3)/3\n",
    "k = (k1+k2)/2\n",
    "\n",
    "#  ,     :\n",
    "print(cosine(v,w))\n",
    "print(cosine(k,v))\n",
    "print(cosine(k,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embdngs(word_list, embdngs_di:dict): \n",
    "    all_embdngs = []\n",
    "    for w in word_list: \n",
    "        embdng = embdngs_di.get(w, None)\n",
    "        if isinstance(embdng, np.ndarray): \n",
    "            all_embdngs.append(embdng)\n",
    "    l = len(all_embdngs) \n",
    "    if l == 0: \n",
    "        return None\n",
    "    else: \n",
    "        return sum(all_embdngs)/l\n",
    "    \n",
    "def make_drug_embdngs_df(df,\n",
    "                         id_clmn:str,\n",
    "                         short_name_clmn:str,\n",
    "                         embdngs_di:dict):\n",
    "    \n",
    "    # make embeddings for all clients drugs:\n",
    "    df= df.groupby(id_clmn)[short_name_clmn].apply(\n",
    "        lambda x: get_embdngs(x, embdngs_di))\n",
    "    \n",
    "    # serie to df:\n",
    "    df = df.reset_index().dropna()\n",
    "    df.reset_index(drop= True, inplace= True)\n",
    "    \n",
    "    # add new clmns:\n",
    "    new_cols = [f'drag_name_{i}' for i in range(1,51)]\n",
    "    df[new_cols] = pd.DataFrame(\n",
    "        df.short_drug_name.to_list(),  \n",
    "        index = df.index)\n",
    "    \n",
    "    # drop clmn with lists\n",
    "    df.drop(\n",
    "        'short_drug_name',\n",
    "        axis=1,\n",
    "        inplace= True\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_emdb_2018df = make_drug_embdngs_df(\n",
    "    prescriptions_2018df,\n",
    "    'member_id',\n",
    "    'short_drug_name',\n",
    "    drg_emdngs)\n",
    "\n",
    "print(drug_emdb_2018df.shape)\n",
    "drug_emdb_2018df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from 2019 \n",
    "prescriptions_2019df = prescriptions_df[prescriptions_df.date_filled.apply(\n",
    "    lambda x: x.split('-')[0] == '2019')].reset_index(drop= True).copy()\n",
    "\n",
    "drug_emdb_2019df = make_drug_embdngs_df(\n",
    "    prescriptions_2019df,\n",
    "    'member_id',\n",
    "    'short_drug_name',\n",
    "    drg_emdngs)\n",
    "\n",
    "print(drug_emdb_2019df.shape)\n",
    "drug_emdb_2019df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate statistics on other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: \n",
    "* dynamic features: how changed drugs and amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_drugs_statistic_features_df:\n",
    "    ''''''\n",
    "    def __init__(self, df): \n",
    "        self.df = df\n",
    "        \n",
    "        # total statistics\n",
    "        \n",
    "        # days_supply\n",
    "        self.ttl_ds_mean = self.df.groupby(\n",
    "            'member_id').clnd_days_supply.mean().mean()\n",
    "        \n",
    "        self.ttl_ds_median = self.df.clnd_days_supply.median()\n",
    "        \n",
    "        self.ttl_ds_max = self.df.clnd_days_supply.max()\n",
    "        \n",
    "        # metric_quantity\n",
    "        self.ttl_mq_mean = self.df.groupby(\n",
    "            'member_id').clnd_metric_quantity.mean().mean()\n",
    "        \n",
    "        self.ttl_mq_median = self.df.clnd_metric_quantity.median()\n",
    "        \n",
    "        self.ttl_mq_max = self.df.clnd_metric_quantity.max()\n",
    "        \n",
    "        # ndc_number\n",
    "        self.ttl_ndc_number_mean = self.df.groupby(\n",
    "            'member_id').ndc_number.count().mean()\n",
    "        \n",
    "        self.ttl_ndc_number_unique_mean = self.df.groupby(\n",
    "            'member_id').ndc_number.nunique().mean()\n",
    "        \n",
    "        \n",
    "    def new_to_relif_ratio(self, clmn):\n",
    "        vc = clmn.dropna().value_counts()\n",
    "        if set(['N','R']) == set(vc.index):\n",
    "            return vc['N']/vc['R'] if vc['R'] > 0 else None\n",
    "        else: \n",
    "            return None\n",
    "\n",
    "    def agg_rules(self, x): \n",
    "        d= {\n",
    "            # ndc_number\n",
    "            'count_ndc_number'       : x['ndc_number'].count(),\n",
    "            'nunique_ndc_number'     : x['ndc_number'].nunique(),\n",
    "            'rel_count_ndc_number'   : x['ndc_number'].count()/self.ttl_ndc_number_mean,\n",
    "            'rel_nunique_ndc_number' : x['ndc_number'].nunique()/self.ttl_ndc_number_unique_mean,\n",
    "\n",
    "            # days_supply \n",
    "            'mean_days_supply'  : x['clnd_days_supply'].mean(), # can be variable\n",
    "            'std_days_supply'   : x['clnd_days_supply'].std(),\n",
    "            'median_days_supply': x['clnd_days_supply'].median(),\n",
    "            'max_days_supply'   : x['clnd_days_supply'].max(),\n",
    "            'min_days_supply'   : x['clnd_days_supply'].min(),\n",
    "\n",
    "            # relative days_supply to total \n",
    "            'rel_mean_days_supply'  : x['clnd_days_supply'].mean()/self.ttl_ds_mean,\n",
    "            'rel_median_days_supply': x['clnd_days_supply'].median()/self.ttl_ds_median,\n",
    "            'rel_max_days_supply'   : x['clnd_days_supply'].max()/self.ttl_ds_max,\n",
    "\n",
    "            # metric_quantity\n",
    "            'mean_metric_quantity'  : x['clnd_metric_quantity'].mean(),\n",
    "            'std_metric_quantity'   : x['clnd_metric_quantity'].std(),\n",
    "            'median_metric_quantity': x['clnd_metric_quantity'].median(),\n",
    "            'max_metric_quantity'   : x['clnd_metric_quantity'].max(),\n",
    "            'min_metric_quantity'   : x['clnd_metric_quantity'].min(),\n",
    "            \n",
    "            # relative metric_quantity to total \n",
    "            'rel_mean_metric_quantity'  : x['clnd_metric_quantity'].mean()/self.ttl_mq_mean,\n",
    "            'rel_median_metric_quantity': x['clnd_metric_quantity'].median()/self.ttl_mq_median,\n",
    "            'rel_max_metric_quantity'   : x['clnd_metric_quantity'].max()/self.ttl_mq_max,\n",
    "            \n",
    "            # new_or_refill\n",
    "            'ratio_new_to_refill'       : self.new_to_relif_ratio(x['new_or_refill'])\n",
    "        }\n",
    "\n",
    "        return pd.Series(d, index= d.keys())\n",
    "    \n",
    "    def group_and_agg_df(self):\n",
    "        return self.df.groupby('member_id').apply(\n",
    "            self.agg_rules).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_presrp_2018df = make_drugs_statistic_features_df(\n",
    "    prescriptions_2018df).group_and_agg_df()\n",
    "print(stats_presrp_2018df.shape)\n",
    "stats_presrp_2018df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescr_features_2018df = prescriptions_2018df[\n",
    "    ['member_id']].drop_duplicates().reset_index(drop= True).copy()\n",
    "print(prescr_features_2018df.shape)\n",
    "\n",
    "prescr_features_2018df = prescr_features_2018df.merge(\n",
    "    drug_emdb_2018df, \n",
    "    on = 'member_id', \n",
    "    how= 'left'\n",
    ")\n",
    "print(prescr_features_2018df.shape)\n",
    "\n",
    "prescr_features_2018df = prescr_features_2018df.merge(\n",
    "    stats_presrp_2018df, \n",
    "    on = 'member_id', \n",
    "    how= 'left'\n",
    ")\n",
    "print(prescr_features_2018df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_presrp_2019df = make_drugs_statistic_features_df(\n",
    "    prescriptions_2019df).group_and_agg_df()\n",
    "print(stats_presrp_2019df.shape)\n",
    "stats_presrp_2019df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescr_features_2019df = prescriptions_2019df[\n",
    "    ['member_id']].drop_duplicates().reset_index(drop= True).copy()\n",
    "print(prescr_features_2019df.shape)\n",
    "\n",
    "prescr_features_2019df = prescr_features_2019df.merge(\n",
    "    drug_emdb_2019df, \n",
    "    on = 'member_id', \n",
    "    how= 'left'\n",
    ")\n",
    "print(prescr_features_2019df.shape)\n",
    "\n",
    "prescr_features_2019df = prescr_features_2019df.merge(\n",
    "    stats_presrp_2019df, \n",
    "    on = 'member_id', \n",
    "    how= 'left'\n",
    ")\n",
    "print(prescr_features_2019df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescr_features_2018df.to_pickle(\n",
    "    '/kaggle/working/prescr_features_2018df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescr_features_2019df.to_pickle(\n",
    "    '/kaggle/working/prescr_features_2019df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:08:11.067157Z",
     "iopub.status.busy": "2021-10-16T16:08:11.066834Z",
     "iopub.status.idle": "2021-10-16T16:08:11.243854Z",
     "shell.execute_reply": "2021-10-16T16:08:11.243131Z",
     "shell.execute_reply.started": "2021-10-16T16:08:11.067127Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\n",
    "    os.path.join(data_path, 'sample_submission.csv'))\n",
    "print(sample_submission_df.shape)\n",
    "sample_submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ouput format:\n",
    "req_columns = sample_submission_df.columns\n",
    "print(f'Required columns: {list(req_columns)},\\nclmns number: {len(req_columns)}')\n",
    "print(sample_submission_df.member_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T09:31:08.058158Z",
     "iopub.status.busy": "2021-10-10T09:31:08.057789Z",
     "iopub.status.idle": "2021-10-10T09:31:08.062957Z",
     "shell.execute_reply": "2021-10-10T09:31:08.062092Z",
     "shell.execute_reply.started": "2021-10-10T09:31:08.058126Z"
    }
   },
   "source": [
    "## train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T07:45:57.672534Z",
     "iopub.status.busy": "2021-10-17T07:45:57.672265Z",
     "iopub.status.idle": "2021-10-17T07:45:57.765835Z",
     "shell.execute_reply": "2021-10-17T07:45:57.764993Z",
     "shell.execute_reply.started": "2021-10-17T07:45:57.672508Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(\n",
    "    os.path.join(data_path, 'train_labels.csv'))\n",
    "print(train_labels_df.shape)\n",
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:08:40.090446Z",
     "iopub.status.busy": "2021-10-16T16:08:40.089714Z",
     "iopub.status.idle": "2021-10-16T16:08:40.104851Z",
     "shell.execute_reply": "2021-10-16T16:08:40.104272Z",
     "shell.execute_reply.started": "2021-10-16T16:08:40.090408Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'member_id nunique: {train_labels_df.member_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:12:57.500764Z",
     "iopub.status.busy": "2021-10-16T16:12:57.500025Z",
     "iopub.status.idle": "2021-10-16T16:12:57.548191Z",
     "shell.execute_reply": "2021-10-16T16:12:57.547406Z",
     "shell.execute_reply.started": "2021-10-16T16:12:57.500717Z"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = pd.read_pickle(\n",
    "    '/kaggle/working/patients_feature_df.pickle')\n",
    "\n",
    "adm_features_2018df = pd.read_pickle(\n",
    "    '/kaggle/working/adm_features_2018df.pickle')\n",
    "\n",
    "dis_features_2018df = pd.read_pickle(\n",
    "    '/kaggle/working/dis_features_2018df.pickle')\n",
    "\n",
    "labs_feature_2018df = pd.read_pickle(\n",
    "    '/kaggle/working/labs_feature_2018_df.pickle')\n",
    "\n",
    "prescr_features_2018df = pd.read_pickle(\n",
    "    '/kaggle/working/prescr_features_2018df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:15:00.17782Z",
     "iopub.status.busy": "2021-10-16T16:15:00.177109Z",
     "iopub.status.idle": "2021-10-16T16:15:00.373315Z",
     "shell.execute_reply": "2021-10-16T16:15:00.372661Z",
     "shell.execute_reply.started": "2021-10-16T16:15:00.177766Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_labels_df[['member_id']].copy()\n",
    "\n",
    "for df in [adm_features_2018df, dis_features_2018df, \n",
    "           labs_feature_2018df, prescr_features_2018df]:\n",
    "    \n",
    "    train_df = train_df.merge(\n",
    "        df, \n",
    "        on = 'member_id', \n",
    "        how= 'left'\n",
    "    )\n",
    "    print(train_df.shape)\n",
    "    \n",
    "# train_df.to_pickle('/kaggle/working/train_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:17:44.108308Z",
     "iopub.status.busy": "2021-10-16T16:17:44.107962Z",
     "iopub.status.idle": "2021-10-16T16:17:44.185884Z",
     "shell.execute_reply": "2021-10-16T16:17:44.184951Z",
     "shell.execute_reply.started": "2021-10-16T16:17:44.108273Z"
    }
   },
   "outputs": [],
   "source": [
    "adm_features_2019df = pd.read_pickle(\n",
    "    '/kaggle/working/adm_features_2019df.pickle')\n",
    "\n",
    "dis_features_2019df = pd.read_pickle(\n",
    "    '/kaggle/working/dis_features_2019df.pickle')\n",
    "\n",
    "labs_feature_2019df = pd.read_pickle(\n",
    "    '/kaggle/working/labs_feature_2019_df.pickle')\n",
    "\n",
    "prescr_features_2019df = pd.read_pickle(\n",
    "    '/kaggle/working/prescr_features_2019df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T16:18:25.813805Z",
     "iopub.status.busy": "2021-10-16T16:18:25.813369Z",
     "iopub.status.idle": "2021-10-16T16:18:26.040452Z",
     "shell.execute_reply": "2021-10-16T16:18:26.039869Z",
     "shell.execute_reply.started": "2021-10-16T16:18:25.813773Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = train_labels_df[['member_id']].copy()\n",
    "\n",
    "for df in [adm_features_2019df, dis_features_2019df, \n",
    "           labs_feature_2019df, prescr_features_2019df]:\n",
    "    \n",
    "    test_df = test_df.merge(\n",
    "        df, \n",
    "        on = 'member_id', \n",
    "        how= 'left'\n",
    "    )\n",
    "    print(test_df.shape)\n",
    "    \n",
    "print(all(test_df.columns == train_df.columns))\n",
    "# test_df.to_pickle('/kaggle/working/test_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:20.639634Z",
     "iopub.status.busy": "2021-10-17T19:08:20.63872Z",
     "iopub.status.idle": "2021-10-17T19:08:23.433338Z",
     "shell.execute_reply": "2021-10-17T19:08:23.431826Z",
     "shell.execute_reply.started": "2021-10-17T19:08:20.63958Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\n",
    "    '/kaggle/input/prepared-features/train_df.pickle')\n",
    "print(train_df.shape)\n",
    "\n",
    "test_df = pd.read_pickle(\n",
    "    '/kaggle/input/prepared-features/test_df.pickle')\n",
    "print(test_df.shape)\n",
    "\n",
    "train_labels_df = pd.read_csv(\n",
    "    '/kaggle/input/eastwood-and-cleef-ml-disease/drive-download-20210929T123943Z-001/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:24.602779Z",
     "iopub.status.busy": "2021-10-17T19:08:24.602484Z",
     "iopub.status.idle": "2021-10-17T19:08:24.637754Z",
     "shell.execute_reply": "2021-10-17T19:08:24.636806Z",
     "shell.execute_reply.started": "2021-10-17T19:08:24.602749Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all(train_labels_df.member_id == train_df.member_id))\n",
    "print(all(train_labels_df.member_id == test_df.member_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T07:19:58.268807Z",
     "iopub.status.busy": "2021-10-17T07:19:58.268029Z",
     "iopub.status.idle": "2021-10-17T07:19:58.288985Z",
     "shell.execute_reply": "2021-10-17T07:19:58.288477Z",
     "shell.execute_reply.started": "2021-10-17T07:19:58.268773Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:29.696777Z",
     "iopub.status.busy": "2021-10-17T19:08:29.696457Z",
     "iopub.status.idle": "2021-10-17T19:08:31.795353Z",
     "shell.execute_reply": "2021-10-17T19:08:31.794399Z",
     "shell.execute_reply.started": "2021-10-17T19:08:29.696747Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val =  iterative_train_test_split(\n",
    "    train_df.drop('member_id', axis= 1).fillna(0).values,\n",
    "    train_labels_df.drop('member_id', axis= 1).values,\n",
    "    test_size = 0.15)\n",
    "\n",
    "print(f'Train shape: {X_train.shape},Val shape {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:31.841848Z",
     "iopub.status.busy": "2021-10-17T19:08:31.840813Z",
     "iopub.status.idle": "2021-10-17T19:08:31.846726Z",
     "shell.execute_reply": "2021-10-17T19:08:31.846093Z",
     "shell.execute_reply.started": "2021-10-17T19:08:31.841809Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_num_dis(x):\n",
    "    df = pd.DataFrame([[i for i in (range(30))],\n",
    "        [sum(x[:,i]) for i in range(30)]]).T\n",
    "    df.columns = ['dis_clmn_number', 'num_dis']\n",
    "    print(f'Zero classes:{df[df.num_dis == 0].dis_clmn_number.values}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:31.936656Z",
     "iopub.status.busy": "2021-10-17T19:08:31.936364Z",
     "iopub.status.idle": "2021-10-17T19:08:32.252769Z",
     "shell.execute_reply": "2021-10-17T19:08:32.251646Z",
     "shell.execute_reply.started": "2021-10-17T19:08:31.936626Z"
    }
   },
   "outputs": [],
   "source": [
    "class_num_dis(y_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:08:32.304958Z",
     "iopub.status.busy": "2021-10-17T19:08:32.304338Z",
     "iopub.status.idle": "2021-10-17T19:08:32.365911Z",
     "shell.execute_reply": "2021-10-17T19:08:32.364968Z",
     "shell.execute_reply.started": "2021-10-17T19:08:32.304915Z"
    }
   },
   "outputs": [],
   "source": [
    "class_num_dis(y_val).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:10:46.445666Z",
     "iopub.status.busy": "2021-10-17T19:10:46.444811Z",
     "iopub.status.idle": "2021-10-17T19:54:36.751273Z",
     "shell.execute_reply": "2021-10-17T19:54:36.750168Z",
     "shell.execute_reply.started": "2021-10-17T19:10:46.445611Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_estimator = xgb.XGBClassifier(\n",
    "    n_estimators = 300,\n",
    "    eval_metric= 'logloss',\n",
    "    use_label_encoder= False\n",
    ") \n",
    "\n",
    "multilabel_model = MultiOutputClassifier(\n",
    "    xgb_estimator,\n",
    ")\n",
    "\n",
    "multilabel_model.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T19:54:36.764688Z",
     "iopub.status.busy": "2021-10-17T19:54:36.764409Z",
     "iopub.status.idle": "2021-10-17T19:54:37.848228Z",
     "shell.execute_reply": "2021-10-17T19:54:37.847358Z",
     "shell.execute_reply.started": "2021-10-17T19:54:36.764658Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(\n",
    "    multilabel_model,\n",
    "    '/kaggle/working/wth_embdngs/model_emdng_ftrs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:03:03.602906Z",
     "iopub.status.busy": "2021-10-17T20:03:03.602588Z",
     "iopub.status.idle": "2021-10-17T20:03:04.213764Z",
     "shell.execute_reply": "2021-10-17T20:03:04.213051Z",
     "shell.execute_reply.started": "2021-10-17T20:03:03.602875Z"
    }
   },
   "outputs": [],
   "source": [
    "val_proba_df = multilabel_model.predict_proba(\n",
    "    X_val)\n",
    "\n",
    "val_proba_df = np.transpose(\n",
    "    [pred[:,1] for pred in val_proba_df])\n",
    "\n",
    "print(val_proba_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select threshold on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:03:15.678224Z",
     "iopub.status.busy": "2021-10-17T20:03:15.677402Z",
     "iopub.status.idle": "2021-10-17T20:03:15.688758Z",
     "shell.execute_reply": "2021-10-17T20:03:15.687816Z",
     "shell.execute_reply.started": "2021-10-17T20:03:15.678184Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_auc_score(y_true, y_pred, thr):\n",
    "    if pd.isnull(thr):\n",
    "        return None\n",
    "    lable_pred = [1 if p > thr else 0 for p in y_pred]\n",
    "    try: \n",
    "        c_auc = roc_auc_score(y_true, lable_pred)\n",
    "        return c_auc\n",
    "    except Exception as e: \n",
    "        return None\n",
    "    \n",
    "def return_top_auc_row(\n",
    "    class_number:int, \n",
    "    y_val_,\n",
    "    val_proba_df_):\n",
    "    '''return list with highest auc'''\n",
    "    \n",
    "    precision_, recall_, thresholds_ = precision_recall_curve(\n",
    "        y_val_,\n",
    "        val_proba_df_)\n",
    "\n",
    "    pr_df = pd.DataFrame([\n",
    "        precision_, \n",
    "        recall_, \n",
    "        thresholds_\n",
    "    ]).T\n",
    "    \n",
    "    pr_df.columns= ['precision', 'recall', 'threshold']\n",
    "\n",
    "    pr_df['custom_auc'] = pr_df['threshold'].apply(\n",
    "        lambda x: custom_auc_score(\n",
    "            y_val_,\n",
    "            val_proba_df_,\n",
    "            x))\n",
    "\n",
    "    pr_df.sort_values(\n",
    "        by= 'custom_auc',\n",
    "        ascending= False, \n",
    "        inplace= True\n",
    "    )\n",
    "    \n",
    "    res_li = [class_number] + list(pr_df.iloc[0])\n",
    "    print(f'Auc:{res_li[-1]}')\n",
    "    return res_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:05:14.23766Z",
     "iopub.status.busy": "2021-10-17T20:05:14.236692Z",
     "iopub.status.idle": "2021-10-17T20:29:03.440201Z",
     "shell.execute_reply": "2021-10-17T20:29:03.439125Z",
     "shell.execute_reply.started": "2021-10-17T20:05:14.237606Z"
    }
   },
   "outputs": [],
   "source": [
    "ftr_df_li = []\n",
    "for i in tqdm(range(30)): \n",
    "    cur_y_val, cur_prob_val = y_val[:,i], val_proba_df[:,i]\n",
    "    ftr_df_li.append(\n",
    "        return_top_auc_row(\n",
    "            i,\n",
    "            cur_y_val,\n",
    "            cur_prob_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:29:03.442247Z",
     "iopub.status.busy": "2021-10-17T20:29:03.442021Z",
     "iopub.status.idle": "2021-10-17T20:29:03.457783Z",
     "shell.execute_reply": "2021-10-17T20:29:03.456925Z",
     "shell.execute_reply.started": "2021-10-17T20:29:03.44222Z"
    }
   },
   "outputs": [],
   "source": [
    "thr_df = pd.DataFrame(ftr_df_li)\n",
    "thr_df.columns = ['dis_number', 'precision', \n",
    "                  'recall', 'threshold', 'top_auc']\n",
    "print(thr_df.shape)\n",
    "thr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:32:43.729385Z",
     "iopub.status.busy": "2021-10-17T21:32:43.729099Z",
     "iopub.status.idle": "2021-10-17T21:32:43.740776Z",
     "shell.execute_reply": "2021-10-17T21:32:43.739767Z",
     "shell.execute_reply.started": "2021-10-17T21:32:43.729357Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(thr_df.top_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:29:03.459173Z",
     "iopub.status.busy": "2021-10-17T20:29:03.458954Z",
     "iopub.status.idle": "2021-10-17T20:29:03.463022Z",
     "shell.execute_reply": "2021-10-17T20:29:03.462416Z",
     "shell.execute_reply.started": "2021-10-17T20:29:03.459148Z"
    }
   },
   "outputs": [],
   "source": [
    "thr_df.to_pickle(\n",
    "    '/kaggle/working/wth_embdngs/thr_df.pickle'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all train DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T20:31:45.248569Z",
     "iopub.status.busy": "2021-10-17T20:31:45.248231Z",
     "iopub.status.idle": "2021-10-17T21:25:10.362188Z",
     "shell.execute_reply": "2021-10-17T21:25:10.361083Z",
     "shell.execute_reply.started": "2021-10-17T20:31:45.248519Z"
    }
   },
   "outputs": [],
   "source": [
    "#    train DF:\n",
    "xgb_estimator = xgb.XGBClassifier(\n",
    "    n_estimators = 300,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    ") \n",
    "\n",
    "full_multilabel_model = MultiOutputClassifier(\n",
    "    xgb_estimator\n",
    ")\n",
    "\n",
    "full_multilabel_model.fit(\n",
    "    train_df.drop('member_id', axis= 1).fillna(0).values,\n",
    "    train_labels_df.drop('member_id', axis= 1).values,\n",
    ")\n",
    "\n",
    "print('Model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:25:10.366655Z",
     "iopub.status.busy": "2021-10-17T21:25:10.366175Z",
     "iopub.status.idle": "2021-10-17T21:25:11.511318Z",
     "shell.execute_reply": "2021-10-17T21:25:11.509833Z",
     "shell.execute_reply.started": "2021-10-17T21:25:10.366601Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(\n",
    "    full_multilabel_model,\n",
    "    '/kaggle/working/wth_embdngs/full_model_no_embdngs.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:26:53.392139Z",
     "iopub.status.busy": "2021-10-17T21:26:53.391835Z",
     "iopub.status.idle": "2021-10-17T21:26:58.076833Z",
     "shell.execute_reply": "2021-10-17T21:26:58.07609Z",
     "shell.execute_reply.started": "2021-10-17T21:26:53.392109Z"
    }
   },
   "outputs": [],
   "source": [
    "test_proba = full_multilabel_model.predict_proba(\n",
    "    test_df.drop('member_id', axis= 1).fillna(0).values\n",
    ")\n",
    "\n",
    "test_proba = np.transpose(\n",
    "    [pred[:,1] for pred in test_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:27:07.377333Z",
     "iopub.status.busy": "2021-10-17T21:27:07.377021Z",
     "iopub.status.idle": "2021-10-17T21:27:07.411935Z",
     "shell.execute_reply": "2021-10-17T21:27:07.410725Z",
     "shell.execute_reply.started": "2021-10-17T21:27:07.3773Z"
    }
   },
   "outputs": [],
   "source": [
    "test_proba_df = pd.DataFrame(test_proba)\n",
    "test_proba_df.columns = list(train_labels_df.columns)[1:]\n",
    "test_proba_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:27:24.25446Z",
     "iopub.status.busy": "2021-10-17T21:27:24.254197Z",
     "iopub.status.idle": "2021-10-17T21:27:24.803272Z",
     "shell.execute_reply": "2021-10-17T21:27:24.802462Z",
     "shell.execute_reply.started": "2021-10-17T21:27:24.254433Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "for clmn, thr_ in zip(test_proba_df.columns, thr_df.threshold): \n",
    "    res_df[clmn] = test_proba_df[clmn].apply(\n",
    "        lambda x: 1 if x > thr_ else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:27:32.378365Z",
     "iopub.status.busy": "2021-10-17T21:27:32.378055Z",
     "iopub.status.idle": "2021-10-17T21:27:32.413798Z",
     "shell.execute_reply": "2021-10-17T21:27:32.413159Z",
     "shell.execute_reply.started": "2021-10-17T21:27:32.378328Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df['member_id'] = test_df.member_id.values\n",
    "res_df = res_df[train_labels_df.columns].copy()\n",
    "print(res_df.shape)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-17T21:27:45.668789Z",
     "iopub.status.busy": "2021-10-17T21:27:45.667925Z",
     "iopub.status.idle": "2021-10-17T21:27:45.895054Z",
     "shell.execute_reply": "2021-10-17T21:27:45.894126Z",
     "shell.execute_reply.started": "2021-10-17T21:27:45.668731Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df.to_csv(\n",
    "    '/kaggle/working/emb_res_df.csv', \n",
    "    index= False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
